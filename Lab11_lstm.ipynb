{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 11: Recurrent and LSTM Neural Networks\n",
    "\n",
    "#### CSC 215 Artificial Intelligence (Spring 2019)\n",
    "\n",
    "#### Dr. Haiquan Chen, California State University, Sacramento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Functions for Tensorflow (Little Gems)\n",
    "\n",
    "The following functions will be used with TensorFlow to help preprocess the data.  They allow you to build the feature vector for a neural network. \n",
    "\n",
    "* Predictors/Inputs \n",
    "    * Fill any missing inputs with the median for that column.  Use **missing_median**.\n",
    "    * Encode textual/categorical values with **encode_text_dummy**.\n",
    "    * Encode numeric values with **encode_numeric_zscore**.\n",
    "* Output\n",
    "    * Discard rows with missing outputs.\n",
    "    * Encode textual/categorical values with **encode_text_index**.\n",
    "    * Do not encode output numeric values.\n",
    "* Convert dataframe to numpy array to create feature vectors (x) and expected output (y) with **to_xy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, collections.Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Structure for Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN is good at predicting something over a sequnce of vectors\n",
    "\n",
    "For example, we might take as input a stock price and volume, to predict if we should buy (1), sell (-1), or hold (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32, 1383], [41, 2928], [39, 8823], [20, 1252], [15, 1532]]\n",
      "[1, -1, 0, -1, 1]\n"
     ]
    }
   ],
   "source": [
    "x = [\n",
    "    [32,1383],\n",
    "    [41,2928],\n",
    "    [39,8823],\n",
    "    [20,1252],\n",
    "    [15,1532]\n",
    "]\n",
    "\n",
    "y = [\n",
    "    1,\n",
    "    -1,\n",
    "    0,\n",
    "    -1,\n",
    "    1\n",
    "]\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Put data to a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>1383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>2928</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>8823</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>1252</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>1532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  volume  y\n",
       "0     32    1383  1\n",
       "1     41    2928 -1\n",
       "2     39    8823  0\n",
       "3     20    1252 -1\n",
       "4     15    1532  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "df = pd.DataFrame({'price':x[:,0], 'volume':x[:,1], 'y':y})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get to ***sequence*** format.  We want to predict something over a sequence, so the data format needs to add a dimension.  \n",
    "\n",
    "### Notice that x should be of 3 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[32, 1383], [41, 2928], [39, 8823], [20, 1252], [15, 1532]], [[35, 8272], [32, 1383], [41, 2928], [39, 8823], [20, 1252]], [[37, 2738], [35, 8272], [32, 1383], [41, 2928], [39, 8823]], [[34, 2845], [37, 2738], [35, 8272], [32, 1383], [41, 2928]], [[32, 2345], [34, 2845], [37, 2738], [35, 8272], [32, 1383]]]\n",
      "[1, -1, 0, -1, 1]\n"
     ]
    }
   ],
   "source": [
    "x = [\n",
    "    [[32,1383],[41,2928],[39,8823],[20,1252],[15,1532]],\n",
    "    [[35,8272],[32,1383],[41,2928],[39,8823],[20,1252]],\n",
    "    [[37,2738],[35,8272],[32,1383],[41,2928],[39,8823]],\n",
    "    [[34,2845],[37,2738],[35,8272],[32,1383],[41,2928]],\n",
    "    [[32,2345],[34,2845],[37,2738],[35,8272],[32,1383]],\n",
    "]\n",
    "\n",
    "y = [\n",
    "    1,\n",
    "    -1,\n",
    "    0,\n",
    "    -1,\n",
    "    1\n",
    "]\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if there is only one feature (stock price), the 3rd dimension must be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[32], [41], [39], [20], [15]], [[35], [32], [41], [39], [20]], [[37], [35], [32], [41], [39]], [[34], [37], [35], [32], [41]], [[32], [34], [37], [35], [32]]]\n",
      "[1, -1, 0, -1, 1]\n"
     ]
    }
   ],
   "source": [
    "x = [\n",
    "    [[32],[41],[39],[20],[15]],\n",
    "    [[35],[32],[41],[39],[20]],\n",
    "    [[37],[35],[32],[41],[39]],\n",
    "    [[34],[37],[35],[32],[41]],\n",
    "    [[32],[34],[37],[35],[32]],\n",
    "]\n",
    "\n",
    "y = [\n",
    "    1,\n",
    "    -1,\n",
    "    0,\n",
    "    -1,\n",
    "    1\n",
    "]\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "So far the neural networks that we’ve examined have always had forward connections.  This manner to connect layers is the reason that ***these networks are called “feedforward.”***  \n",
    "\n",
    "\n",
    "In Recurrent neural networks, \"backward/recurrent connections\" are also allowed. A \"backward/recurrent connection\" occurs when a connection is formed between a neuron and a neuron at the same level or a neuron at a previous level.\n",
    "\n",
    "\n",
    "Most recurrent neural network architectures maintain \"state\" in the recurrent connections.  ***A recurrent neural network’s state acts as a short-term memory (context) for the neural network.***  Consequently, a recurrent neural network will not always produce the same output for a given input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding LSTM\n",
    "\n",
    "Long Short Term Neural Network (LSTM) are ***a type of recurrent unit***.  For TensorFlow, LSTM is provided as a layer type that can be combined with other layer types, such as dense.  \n",
    "\n",
    "https://keras.io/layers/recurrent/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " ***The following diagram shows an LSTM unit over three time slices***: the current time slice (t), as well as the previous (t-1) and next (t+1) slice:\n",
    "\n",
    "![LSTM Layers](images/lab11_lstm1.png \"LSTM Layers\")\n",
    "\n",
    "The values $\\hat{y}$ are the output from the unit, the values ($x$) are the input to the unit and the values $c$ are the context values.  Both the output and context values are always fed to the next time slice. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout in RNN\n",
    "\n",
    "Tensorflow privide parameters for you to use dropout in RNN.  In LSTM, you can define two types of dropout. \n",
    "\n",
    "***Regular dropout***. Applied on the inputs and/or the outputs.  They mask (or \"drop\") the vertical connections from x_t and to h_t in the picture below. \n",
    "\n",
    "***Recurrent dropout***. Recurrent dropout masks (or \"drops\") the horizontal connections between the recurrent units in the picture below.\n",
    "\n",
    "\n",
    "![LSTM Layers](images/lab11_lstm3.png \"Dropout in LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Example for Classification\n",
    "\n",
    "The following code creates the LSTM network.  This is an example of RNN classification.  The following code trains on a data set (x) with a max sequence size of 6 (columns) and 6 training elements (rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "\n",
    "# assume we have 4 classes\n",
    "num_classes = 4  \n",
    "\n",
    "x = [\n",
    "    [[0],[1],[1],[0],[0],[0]],\n",
    "    [[0],[0],[0],[2],[2],[0]],\n",
    "    [[0],[0],[0],[0],[3],[3]],\n",
    "    [[0],[2],[2],[0],[0],[0]],\n",
    "    [[0],[0],[3],[3],[0],[0]],\n",
    "    [[0],[0],[0],[0],[1],[1]]\n",
    "]\n",
    "\n",
    "\n",
    "# Tensorflow likes float32 and int32\n",
    "x = np.array(x, dtype=np.float32)\n",
    "y = np.array([1,2,3,2,3,1], dtype=np.int32)\n",
    "\n",
    "\n",
    "# Convert y2to dummy variables (one-hot encoding for classification problem)\n",
    "\n",
    "y_2 = keras.utils.to_categorical(y, num_classes)\n",
    "y_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Like CNN,  input_shape is the shape of each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.3891 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1.3786 - acc: 0.6667\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.3834 - acc: 0.3333\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1.3718 - acc: 0.3333\n",
      "Epoch 5/100\n",
      " - 0s - loss: 1.3583 - acc: 0.6667\n",
      "Epoch 6/100\n",
      " - 0s - loss: 1.3567 - acc: 0.5000\n",
      "Epoch 7/100\n",
      " - 0s - loss: 1.3495 - acc: 0.3333\n",
      "Epoch 8/100\n",
      " - 0s - loss: 1.3566 - acc: 0.3333\n",
      "Epoch 9/100\n",
      " - 0s - loss: 1.3670 - acc: 0.1667\n",
      "Epoch 10/100\n",
      " - 0s - loss: 1.3438 - acc: 0.3333\n",
      "Epoch 11/100\n",
      " - 0s - loss: 1.3195 - acc: 0.3333\n",
      "Epoch 12/100\n",
      " - 0s - loss: 1.3348 - acc: 0.3333\n",
      "Epoch 13/100\n",
      " - 0s - loss: 1.3151 - acc: 0.5000\n",
      "Epoch 14/100\n",
      " - 0s - loss: 1.3169 - acc: 0.1667\n",
      "Epoch 15/100\n",
      " - 0s - loss: 1.2788 - acc: 0.3333\n",
      "Epoch 16/100\n",
      " - 0s - loss: 1.2660 - acc: 0.3333\n",
      "Epoch 17/100\n",
      " - 0s - loss: 1.2616 - acc: 0.3333\n",
      "Epoch 18/100\n",
      " - 0s - loss: 1.2516 - acc: 0.3333\n",
      "Epoch 19/100\n",
      " - 0s - loss: 1.2761 - acc: 0.6667\n",
      "Epoch 20/100\n",
      " - 0s - loss: 1.2521 - acc: 0.5000\n",
      "Epoch 21/100\n",
      " - 0s - loss: 1.2619 - acc: 0.1667\n",
      "Epoch 22/100\n",
      " - 0s - loss: 1.2531 - acc: 0.1667\n",
      "Epoch 23/100\n",
      " - 0s - loss: 1.2113 - acc: 0.5000\n",
      "Epoch 24/100\n",
      " - 0s - loss: 1.1857 - acc: 0.5000\n",
      "Epoch 25/100\n",
      " - 0s - loss: 1.1911 - acc: 0.6667\n",
      "Epoch 26/100\n",
      " - 0s - loss: 1.2998 - acc: 0.1667\n",
      "Epoch 27/100\n",
      " - 0s - loss: 1.1391 - acc: 0.5000\n",
      "Epoch 28/100\n",
      " - 0s - loss: 1.1714 - acc: 0.5000\n",
      "Epoch 29/100\n",
      " - 0s - loss: 1.1073 - acc: 0.5000\n",
      "Epoch 30/100\n",
      " - 0s - loss: 1.1804 - acc: 0.5000\n",
      "Epoch 31/100\n",
      " - 0s - loss: 1.1584 - acc: 0.3333\n",
      "Epoch 32/100\n",
      " - 0s - loss: 1.0752 - acc: 0.5000\n",
      "Epoch 33/100\n",
      " - 0s - loss: 1.0725 - acc: 0.3333\n",
      "Epoch 34/100\n",
      " - 0s - loss: 1.1411 - acc: 0.5000\n",
      "Epoch 35/100\n",
      " - 0s - loss: 1.0745 - acc: 0.3333\n",
      "Epoch 36/100\n",
      " - 0s - loss: 1.0703 - acc: 0.3333\n",
      "Epoch 37/100\n",
      " - 0s - loss: 1.2339 - acc: 0.1667\n",
      "Epoch 38/100\n",
      " - 0s - loss: 1.0501 - acc: 0.3333\n",
      "Epoch 39/100\n",
      " - 0s - loss: 1.1318 - acc: 0.3333\n",
      "Epoch 40/100\n",
      " - 0s - loss: 1.1084 - acc: 0.1667\n",
      "Epoch 41/100\n",
      " - 0s - loss: 1.0943 - acc: 0.1667\n",
      "Epoch 42/100\n",
      " - 0s - loss: 1.0674 - acc: 0.5000\n",
      "Epoch 43/100\n",
      " - 0s - loss: 1.0097 - acc: 0.3333\n",
      "Epoch 44/100\n",
      " - 0s - loss: 1.0002 - acc: 0.5000\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.9947 - acc: 0.5000\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.9517 - acc: 0.5000\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.9785 - acc: 0.5000\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.9220 - acc: 0.6667\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.9360 - acc: 0.5000\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.8992 - acc: 0.8333\n",
      "Epoch 51/100\n",
      " - 0s - loss: 1.0037 - acc: 0.5000\n",
      "Epoch 52/100\n",
      " - 0s - loss: 1.1025 - acc: 0.3333\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.9623 - acc: 0.6667\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.8816 - acc: 0.6667\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.9722 - acc: 0.5000\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.8388 - acc: 0.6667\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.9910 - acc: 0.3333\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.8609 - acc: 0.5000\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.7780 - acc: 0.6667\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.8449 - acc: 0.6667\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.8320 - acc: 0.5000\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.8777 - acc: 0.5000\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.7162 - acc: 0.6667\n",
      "Epoch 64/100\n",
      " - 0s - loss: 1.0188 - acc: 0.5000\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.7145 - acc: 0.8333\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.6877 - acc: 0.8333\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.9267 - acc: 0.6667\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.7052 - acc: 0.6667\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.9180 - acc: 0.5000\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.6967 - acc: 0.6667\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.7913 - acc: 0.6667\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.8697 - acc: 0.6667\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.5489 - acc: 0.8333\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.5152 - acc: 0.8333\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.8185 - acc: 0.6667\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.5068 - acc: 0.8333\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.7326 - acc: 0.6667\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.4861 - acc: 0.8333\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.4506 - acc: 0.8333\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.8029 - acc: 0.6667\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.5990 - acc: 0.8333\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.4392 - acc: 0.8333\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.4211 - acc: 0.8333\n",
      "Epoch 84/100\n",
      " - 0s - loss: 1.2909 - acc: 0.6667\n",
      "Epoch 85/100\n",
      " - 0s - loss: 1.0162 - acc: 0.6667\n",
      "Epoch 86/100\n",
      " - 0s - loss: 1.5117 - acc: 0.5000\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.7454 - acc: 0.8333\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.5294 - acc: 0.8333\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.4066 - acc: 0.8333\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.6977 - acc: 0.6667\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.7555 - acc: 0.6667\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.4662 - acc: 0.8333\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.5083 - acc: 0.6667\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.4601 - acc: 0.8333\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.7548 - acc: 0.6667\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.8277 - acc: 0.6667\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.4390 - acc: 0.8333\n",
      "Epoch 98/100\n",
      " - 0s - loss: 1.0575 - acc: 0.5000\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.5547 - acc: 0.8333\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.6479 - acc: 0.8333\n",
      "Predicted classes: [1 2 3 1 2 1]\n",
      "Expected classes: [1 2 3 2 3 1]\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# each sequence has 6 members and each member is 1-dimentinal\n",
    "\n",
    "#Like CNN,  input_shape is the shape of each sample\n",
    "\n",
    "model.add(LSTM(128, activation='tanh', dropout=0.2, recurrent_dropout=0.2, input_shape=(6, 1)))\n",
    "model.add(Dense(4, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x, y_2,verbose=2, epochs=100)\n",
    "pred = model.predict(x)\n",
    "\n",
    "predict_classes = np.argmax(pred,axis=1)\n",
    "print(\"Predicted classes:\",predict_classes)\n",
    "print(\"Expected classes:\",y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict any ad hoc sequence using trained model\n",
    "\n",
    "For example  [[0],[0],[0],[0],[0],[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0],[0],[0],[0],[0],[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_1_input to have 3 dimensions, but got array with shape (6, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-21854b1e4784>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1145\u001b[0m                              'argument.')\n\u001b[0;32m   1146\u001b[0m         \u001b[1;31m# Validate user data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 749\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    125\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    128\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected lstm_1_input to have 3 dimensions, but got array with shape (6, 1)"
     ]
    }
   ],
   "source": [
    "x = np.array(x, dtype=np.float32)  \n",
    "\n",
    "pred = model.predict(x)\n",
    "\n",
    "print(x)\n",
    "\n",
    "print(\"Prediction:\", np.argmax(pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why?  \n",
    "\n",
    "### Remeber x must be a 3D array!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [1.]]]\n",
      "Prediction: 1\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[[0],[0],[0],[0],[0],[1]]])\n",
    "\n",
    "x = np.array(x, dtype=np.float32)  \n",
    "\n",
    "pred = model.predict(x)\n",
    "\n",
    "print(x)\n",
    "\n",
    "print(\"Prediction:\", np.argmax(pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Example for Regression\n",
    "\n",
    "An example of RNN regression to predict sunspots.  The data files needed for this example can be found at the following location.\n",
    "\n",
    "* [Sunspot Data Files](http://www.sidc.be/silso/datafiles#total)\n",
    "\n",
    "http://www.sidc.be/silso/infosndtot\n",
    "\n",
    "The following code is used to load the sunspot file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dec_year</th>\n",
       "      <th>sn_value</th>\n",
       "      <th>sn_error</th>\n",
       "      <th>obs_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1818.001</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1818.004</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1818.007</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1818.010</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1818.012</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1818.015</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1818.018</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1818.021</td>\n",
       "      <td>65</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1818.023</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1818.026</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  dec_year  sn_value  sn_error  obs_num\n",
       "0  1818      1    1  1818.001        -1      -1.0        0\n",
       "1  1818      1    2  1818.004        -1      -1.0        0\n",
       "2  1818      1    3  1818.007        -1      -1.0        0\n",
       "3  1818      1    4  1818.010        -1      -1.0        0\n",
       "4  1818      1    5  1818.012        -1      -1.0        0\n",
       "5  1818      1    6  1818.015        -1      -1.0        0\n",
       "6  1818      1    7  1818.018        -1      -1.0        0\n",
       "7  1818      1    8  1818.021        65      10.2        1\n",
       "8  1818      1    9  1818.023        -1      -1.0        0\n",
       "9  1818      1   10  1818.026        -1      -1.0        0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = \"./data/\"\n",
    "    \n",
    "filename = os.path.join(path,\"SN_d_tot_V2.0.csv\")   \n",
    "names = ['year', 'month', 'day', 'dec_year', 'sn_value' , 'sn_error', 'obs_num']\n",
    "df = pd.read_csv(filename, sep=';', header=None, names=names, index_col=False)\n",
    "\n",
    "# index_col=False forces pandas not to use the first column as the index\n",
    "\n",
    "df[0:10]\n",
    "\n",
    "# -1 means NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending file:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dec_year</th>\n",
       "      <th>sn_value</th>\n",
       "      <th>sn_error</th>\n",
       "      <th>obs_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73159</th>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>2018.303</td>\n",
       "      <td>28</td>\n",
       "      <td>1.4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73160</th>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>2018.305</td>\n",
       "      <td>22</td>\n",
       "      <td>1.9</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73161</th>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>2018.308</td>\n",
       "      <td>23</td>\n",
       "      <td>1.3</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73162</th>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>2018.311</td>\n",
       "      <td>22</td>\n",
       "      <td>1.1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73163</th>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>2018.314</td>\n",
       "      <td>18</td>\n",
       "      <td>1.7</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73164</th>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>2018.316</td>\n",
       "      <td>14</td>\n",
       "      <td>1.2</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73165</th>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>2018.319</td>\n",
       "      <td>14</td>\n",
       "      <td>2.9</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73166</th>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>2018.322</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73167</th>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>2018.325</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73168</th>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>2018.327</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  month  day  dec_year  sn_value  sn_error  obs_num\n",
       "73159  2018      4   21  2018.303        28       1.4        9\n",
       "73160  2018      4   22  2018.305        22       1.9       30\n",
       "73161  2018      4   23  2018.308        23       1.3       27\n",
       "73162  2018      4   24  2018.311        22       1.1       16\n",
       "73163  2018      4   25  2018.314        18       1.7       37\n",
       "73164  2018      4   26  2018.316        14       1.2       38\n",
       "73165  2018      4   27  2018.319        14       2.9       25\n",
       "73166  2018      4   28  2018.322         0       0.0       32\n",
       "73167  2018      4   29  2018.325         0       0.0       23\n",
       "73168  2018      4   30  2018.327         0       0.0       31"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Ending file:\")\n",
    "df[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The missing values are marked by -1 \n",
    "\n",
    "df = df[(df['sn_value'] != -1) & (df['obs_num'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69922, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dec_year</th>\n",
       "      <th>sn_value</th>\n",
       "      <th>sn_error</th>\n",
       "      <th>obs_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1818.021</td>\n",
       "      <td>65</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1818.034</td>\n",
       "      <td>37</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1818.045</td>\n",
       "      <td>77</td>\n",
       "      <td>11.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1818.048</td>\n",
       "      <td>98</td>\n",
       "      <td>12.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1818.051</td>\n",
       "      <td>105</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1818.067</td>\n",
       "      <td>25</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1818.075</td>\n",
       "      <td>38</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1818</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1818.078</td>\n",
       "      <td>20</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1818</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1818.092</td>\n",
       "      <td>17</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1818</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1818.097</td>\n",
       "      <td>20</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1818</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1818.100</td>\n",
       "      <td>25</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1818</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1818.108</td>\n",
       "      <td>87</td>\n",
       "      <td>11.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  month  day  dec_year  sn_value  sn_error  obs_num\n",
       "7   1818      1    8  1818.021        65      10.2        1\n",
       "12  1818      1   13  1818.034        37       7.7        1\n",
       "16  1818      1   17  1818.045        77      11.1        1\n",
       "17  1818      1   18  1818.048        98      12.6        1\n",
       "18  1818      1   19  1818.051       105      13.0        1\n",
       "24  1818      1   25  1818.067        25       6.3        1\n",
       "27  1818      1   28  1818.075        38       7.8        1\n",
       "28  1818      1   29  1818.078        20       5.7        1\n",
       "33  1818      2    3  1818.092        17       5.2        1\n",
       "35  1818      2    5  1818.097        20       5.7        1\n",
       "36  1818      2    6  1818.100        25       6.3        1\n",
       "39  1818      2    9  1818.108        87      11.8        1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we want to predict a SN value based on the $N$ preceding values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 63227 records.\n",
      "Test set has 6695 records.\n"
     ]
    }
   ],
   "source": [
    "df_train = df[df['year']<2000]\n",
    "df_test = df[df['year']>=2000]\n",
    "\n",
    "spots_train = df_train['sn_value'].tolist()\n",
    "spots_test = df_test['sn_value'].tolist()\n",
    "\n",
    "print(\"Training set has {} records.\".format(len(spots_train)))\n",
    "print(\"Test set has {} records.\".format(len(spots_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequentialize to create x and y in the format RNN likes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def to_sequences(seq_size, data):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data)-SEQUENCE_SIZE-1):\n",
    "        #print(i)\n",
    "        window = data[i:(i+SEQUENCE_SIZE)]\n",
    "        after_window = data[i+SEQUENCE_SIZE]\n",
    "        window = [[x] for x in window]\n",
    "        #print(\"{} - {}\".format(window,after_window))\n",
    "        x.append(window)\n",
    "        y.append(after_window)\n",
    "        \n",
    "    return np.array(x),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (63216, 10, 1)\n",
      "Shape of x_test: (6684, 10, 1)\n",
      "Shape of y_train: (63216,)\n",
      "Shape of y_test: (6684,)\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_SIZE = 10\n",
    "x_train,y_train = to_sequences(SEQUENCE_SIZE,spots_train)\n",
    "x_test,y_test = to_sequences(SEQUENCE_SIZE,spots_test)\n",
    "\n",
    "print(\"Shape of x_train: {}\".format(x_train.shape))\n",
    "print(\"Shape of x_test: {}\".format(x_test.shape))\n",
    "print(\"Shape of y_train: {}\".format(y_train.shape))\n",
    "print(\"Shape of y_test: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 65],\n",
       "        [ 37],\n",
       "        [ 77],\n",
       "        [ 98],\n",
       "        [105],\n",
       "        [ 25],\n",
       "        [ 38],\n",
       "        [ 20],\n",
       "        [ 17],\n",
       "        [ 20]],\n",
       "\n",
       "       [[ 37],\n",
       "        [ 77],\n",
       "        [ 98],\n",
       "        [105],\n",
       "        [ 25],\n",
       "        [ 38],\n",
       "        [ 20],\n",
       "        [ 17],\n",
       "        [ 20],\n",
       "        [ 25]],\n",
       "\n",
       "       [[ 77],\n",
       "        [ 98],\n",
       "        [105],\n",
       "        [ 25],\n",
       "        [ 38],\n",
       "        [ 20],\n",
       "        [ 17],\n",
       "        [ 20],\n",
       "        [ 25],\n",
       "        [ 87]],\n",
       "\n",
       "       [[ 98],\n",
       "        [105],\n",
       "        [ 25],\n",
       "        [ 38],\n",
       "        [ 20],\n",
       "        [ 17],\n",
       "        [ 20],\n",
       "        [ 25],\n",
       "        [ 87],\n",
       "        [192]],\n",
       "\n",
       "       [[105],\n",
       "        [ 25],\n",
       "        [ 38],\n",
       "        [ 20],\n",
       "        [ 17],\n",
       "        [ 20],\n",
       "        [ 25],\n",
       "        [ 87],\n",
       "        [192],\n",
       "        [ 73]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25,  87, 192,  73,  82])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ready to train a RNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Train on 63216 samples, validate on 6684 samples\n",
      "Epoch 1/10\n",
      " - 10s - loss: 1405.1794 - val_loss: 335.3967\n",
      "Epoch 2/10\n",
      " - 9s - loss: 625.6281 - val_loss: 281.1883\n",
      "Epoch 3/10\n",
      " - 9s - loss: 621.4315 - val_loss: 249.5758\n",
      "Epoch 4/10\n",
      " - 9s - loss: 610.0931 - val_loss: 362.8855\n",
      "Epoch 5/10\n",
      " - 9s - loss: 603.6360 - val_loss: 278.9313\n",
      "Epoch 6/10\n",
      " - 9s - loss: 604.6408 - val_loss: 323.5103\n",
      "Epoch 7/10\n",
      " - 9s - loss: 604.1804 - val_loss: 257.7712\n",
      "Epoch 8/10\n",
      " - 9s - loss: 608.8451 - val_loss: 350.9319\n",
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1e8d0b748>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(64, dropout=0.1, recurrent_dropout=0.1, input_shape=(SEQUENCE_SIZE, 1)))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "print('Train...')\n",
    "\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2, epochs=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (RMSE): 18.733176621473262\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced topics when using LSTM\n",
    "\n",
    "https://keras.io/layers/recurrent/\n",
    "\n",
    "\n",
    "### Accessing the hidden state output   $\\hat{y}$  for each time slice\n",
    "\n",
    "\n",
    "It is possible to access the hidden state output $\\hat{y}$ (the cell output) for each time slice, which can be useful when developing sophisticated recurrent neural network architectures, such as the encoder-decoder model. This can be done by setting the ***return_sequences parameter to True*** when defining the LSTM layer\n",
    "\n",
    "***You must set return_sequences=True when stacking multiple LSTM layers.***\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(..., return_sequences=True, input_shape=(...)))\n",
    "\n",
    "model.add(LSTM(..., return_sequences=True))\n",
    "\n",
    "model.add(LSTM(..., return_sequences=True))\n",
    "\n",
    "model.add(LSTM(...))\n",
    "\n",
    "model.add(Dense(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the context values (internal state) $c$ for each time slice\n",
    "\n",
    "***the return_state argument provides access to the context values (internal state) $c$ for each time slice***\n",
    "\n",
    "\n",
    "For example, we can access both the sequence of hidden state output and the internal states at the same time.\n",
    "\n",
    "This can be done as follows:\n",
    "\n",
    "LSTM(..., return_sequences=True, return_state=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "* [Google Colab](https://colab.research.google.com/) - Free web based platform that includes Python, Juypter Notebooks, and TensorFlow with free GPU support.  No setup needed.\n",
    "* [IBM Cognitive Class Labs](https://www.datascientistworkbench.com) - Free web based platform that includes Python, Juypter Notebooks, and TensorFlow.  No setup needed.\n",
    "* [Python Anaconda](https://www.continuum.io/downloads) - Python distribution that includes many data science packages, such as Numpy, Scipy, Scikit-Learn, Pandas, and much more.\n",
    "* [TensorFlow](https://www.tensorflow.org/) - Google's mathematics package for deep learning.\n",
    "* [Kaggle](https://www.kaggle.com/) - Competitive data science.  Good source of sample data.\n",
    "* T81-558: Applications of Deep Neural Networks. Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
